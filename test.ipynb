{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8ad333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "class SearchAgent(AssistantAgent):\n",
    "    \"\"\"\n",
    "    Agent that performs factual web lookups using DuckDuckGo and Wikipedia,\n",
    "    then summarizes the result using an LLM (model_client).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name=\"search\", model_client=None):\n",
    "        super().__init__(\n",
    "            name=name,\n",
    "            model_client=model_client,\n",
    "            system_message=(\n",
    "                \"You are the SearchAgent. Given a query, you fetch factual information from the DuckDuckGo \"\n",
    "                \"Instant Answer API and Wikipedia, then generate a natural and concise summary using the LLM. \"\n",
    "                \"Avoid simulating sources. Prioritize real-world facts.\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    async def search(self, query: str) -> str:\n",
    "        cleaned_query = self._simplify_query(query)\n",
    "        ddg_result, wiki_result = await self._run_parallel_searches(cleaned_query, query)\n",
    "\n",
    "        if not ddg_result and not wiki_result:\n",
    "            return f\"â„¹ï¸ No useful information found for \\\"{query}\\\" from either DuckDuckGo or Wikipedia.\"\n",
    "\n",
    "        summary = await self._summarize_with_llm(ddg_result, wiki_result)\n",
    "        return f\"ðŸ“˜ Summary:\\n{summary}\"\n",
    "\n",
    "    async def _run_parallel_searches(self, ddg_query: str, wiki_query: str):\n",
    "        return await asyncio.gather(\n",
    "            self._search_duckduckgo(ddg_query),\n",
    "            self._search_wikipedia(wiki_query)\n",
    "        )\n",
    "\n",
    "    async def _search_duckduckgo(self, query: str) -> str:\n",
    "        url = \"https://api.duckduckgo.com/\"\n",
    "        params = {\n",
    "            \"q\": query,\n",
    "            \"format\": \"json\",\n",
    "            \"no_redirect\": 1,\n",
    "            \"no_html\": 1,\n",
    "            \"skip_disambig\": 1\n",
    "        }\n",
    "        try:\n",
    "            async with aiohttp.ClientSession(trust_env=True) as sess:\n",
    "                async with sess.get(url, params=params, timeout=5) as resp:\n",
    "                    data = await resp.json(content_type=None)\n",
    "            return data.get(\"AbstractText\", \"\").strip()\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    async def _search_wikipedia(self, query: str) -> str:\n",
    "        url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{query.replace(' ', '_')}\"\n",
    "        try:\n",
    "            async with aiohttp.ClientSession(trust_env=True) as sess:\n",
    "                async with sess.get(url, timeout=5) as resp:\n",
    "                    if resp.status != 200:\n",
    "                        return \"\"\n",
    "                    data = await resp.json()\n",
    "                    return data.get(\"extract\", \"\").strip()\n",
    "        except Exception:\n",
    "            return \"\"\n",
    "\n",
    "    async def _summarize_with_llm(self, ddg_text: str, wiki_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Use LLM (model_client) to summarize and deduplicate DDG and Wikipedia responses.\n",
    "        \"\"\"\n",
    "        prompt = (\n",
    "            \"You are a smart summarizer. Given two factual text sources about the same topic, \"\n",
    "            \"summarize them into a single clean, natural-sounding paragraph without repetition. \"\n",
    "            \"If both sources are similar, merge the information without duplication. \"\n",
    "            \"Avoid mentioning the sources directly.\\n\\n\"\n",
    "            f\"Source 1 (DuckDuckGo):\\n{ddg_text or '[empty]'}\\n\\n\"\n",
    "            f\"Source 2 (Wikipedia):\\n{wiki_text or '[empty]'}\\n\\n\"\n",
    "            \"Final Summary:\"\n",
    "        )\n",
    "        try:\n",
    "            response = await self.model_client.aask(prompt)\n",
    "            return response.strip()\n",
    "        except Exception as e:\n",
    "            return f\"âŒ LLM summarization failed: {e}\"\n",
    "\n",
    "    def _simplify_query(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Optionally simplify/clean the user query for use in search APIs.\n",
    "        \"\"\"\n",
    "        return query.strip().split(\" and \")[0].split(\"?\")[0].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6afffff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf302b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
